{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers==4.35.2 in c:\\users\\mehar\\appdata\\roaming\\python\\python311\\site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.35.2) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\mehar\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.35.2) (0.19.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mehar\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.35.2) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.35.2) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.35.2) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.35.2) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.35.2) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\mehar\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.35.2) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\mehar\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.35.2) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.35.2) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mehar\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers==4.35.2) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers==4.35.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers==4.35.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers==4.35.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers==4.35.2) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from data_utils import create_dataset, create_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_feats(model, tokenizer, data_loader, max_length, device, modality='text', desc='Get feats'):\n",
    "    text_ids = []\n",
    "    text_embeds = []\n",
    "    text_atts = []\n",
    "    text_outputs = []\n",
    "\n",
    "    for text in tqdm(data_loader, total=len(data_loader), desc=desc):\n",
    "        text_input = tokenizer(text, padding='max_length', truncation=True, max_length=max_length,\n",
    "                               return_tensors=\"pt\").to(device)\n",
    "        text_output = model.encoder(text_input.input_ids, attention_mask=text_input.attention_mask,\n",
    "                                    return_dict=True)\n",
    "        text_embed = torch.nn.functional.normalize(model.proj(text_output.last_hidden_state[:, 0, :]), dim=-1)\n",
    "\n",
    "        text_ids.append(text_input.input_ids)\n",
    "        text_atts.append(text_input.attention_mask)\n",
    "        text_embeds.append(text_embed)\n",
    "        if modality == 'text':\n",
    "            text_outputs.append(text_output.last_hidden_state.cpu())\n",
    "\n",
    "    text_ids = torch.cat(text_ids, dim=0)\n",
    "    text_atts = torch.cat(text_atts, dim=0)\n",
    "    text_embeds = torch.cat(text_embeds, dim=0)\n",
    "    if modality == 'text':\n",
    "        text_outputs = torch.cat(text_outputs, dim=0)\n",
    "    return text_ids, text_atts, text_embeds, text_outputs\n",
    "\n",
    "\n",
    "def get_eos_vec(hidden_state, source_ids, eos_token_id):\n",
    "    eos_mask = source_ids.eq(eos_token_id)\n",
    "    if len(torch.unique(eos_mask.sum(1))) > 1:\n",
    "        raise ValueError(\"All examples must have the same number of <eos> tokens.\")\n",
    "    dec_vec = hidden_state[eos_mask, :].view(hidden_state.size(0), -1, hidden_state.size(-1))[:, -1, :]\n",
    "    return dec_vec\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def match_evaluation(model, text_feats, code_feats, tokenizer, device, top_k, img2txt):\n",
    "    start_time = time.time()\n",
    "\n",
    "    text_ids, text_atts, text_embeds, text_outputs = text_feats\n",
    "    code_ids, code_atts, code_embeds, _ = code_feats\n",
    "    code_ids[:, 0] = tokenizer.enc_token_id\n",
    "\n",
    "    sims_matrix = text_embeds @ code_embeds.t()\n",
    "    score_matrix_i2t = torch.full((text_ids.size(0), code_ids.size(0)), -100.0).to(device)\n",
    "\n",
    "    for i, sims in enumerate(tqdm(sims_matrix, desc=f'Evaluate text-code matching with top {top_k} candidates:')):\n",
    "        topk_sim, topk_idx = sims.topk(k=top_k, dim=0)\n",
    "        encoder_output = text_outputs[i].repeat(top_k, 1, 1).to(device)\n",
    "        encoder_att = text_atts[i].repeat(top_k, 1).to(device)\n",
    "        code_ids[:, 0] = tokenizer.enc_token_id\n",
    "        output = model.decoder(code_ids[topk_idx],\n",
    "                               attention_mask=code_atts[topk_idx],\n",
    "                               encoder_hidden_states=encoder_output,\n",
    "                               encoder_attention_mask=encoder_att,\n",
    "                               return_dict=True,\n",
    "                               )\n",
    "        output_vec = get_eos_vec(output.last_hidden_state, code_ids[topk_idx], tokenizer.eos_token_id)\n",
    "        score = model.itm_head(output_vec)[:, 1]\n",
    "        score_matrix_i2t[i, topk_idx] = score + topk_sim\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print('Evaluation time {}'.format(total_time_str))\n",
    "\n",
    "    scores_i2t = score_matrix_i2t.cpu().numpy()\n",
    "\n",
    "    ranks = np.ones(scores_i2t.shape[0]) * -1\n",
    "\n",
    "    for index, score in enumerate(scores_i2t):\n",
    "        inds = np.argsort(score)[::-1]\n",
    "        ranks[index] = np.where(inds == img2txt[index])[0][0]\n",
    "\n",
    "    # Compute metrics\n",
    "    tr1 = 100.0 * len(np.where(ranks < 1)[0]) / len(ranks)\n",
    "    tr5 = 100.0 * len(np.where(ranks < 5)[0]) / len(ranks)\n",
    "    tr10 = 100.0 * len(np.where(ranks < 10)[0]) / len(ranks)\n",
    "    mrr = 100.0 * np.mean(1 / (ranks + 1))\n",
    "\n",
    "    eval_result = {'r1': tr1,\n",
    "                   'r5': tr5,\n",
    "                   'r10': tr10,\n",
    "                   'mrr': mrr}\n",
    "    return eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating retrieval dataset\n",
      "Read 24927 data from ./dataset/CSN/ruby/train.jsonl\n",
      "Read 1400 data from ./dataset/CSN/ruby/valid.jsonl\n",
      "Read 4360 data from ./dataset/CSN/ruby/codebase.jsonl\n",
      "Read 1261 data from ./dataset/CSN/ruby/test.jsonl\n",
      "Read 4360 data from ./dataset/CSN/ruby/codebase.jsonl\n",
      "Read 4360 data from ./dataset/CSN/ruby/codebase.jsonl\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized model identifier in Salesforce/codet5p-220m-bimodal. Should contains one of 'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', 'xlm', 'roberta', 'ctrl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m _, _, test_dataset, code_dataset \u001b[38;5;241m=\u001b[39m create_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./dataset/CSN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m test_loader, code_loader \u001b[38;5;241m=\u001b[39m create_loader([test_dataset, code_dataset], [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[0;32m      6\u001b[0m                                              batch_size\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m],\n\u001b[0;32m      7\u001b[0m                                              num_workers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m], is_trains\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m], collate_fns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[1;32m----> 9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSalesforce/codet5p-220m-bimodal\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39menc_token_id \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[ENC]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSalesforce/codet5p-220m-bimodal\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_auto.py:122\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mctrl\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pretrained_model_name_or_path:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CTRLTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized model identifier in \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Should contains one of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai-gpt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransfo-xl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxlnet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    124\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxlm\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroberta\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mctrl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pretrained_model_name_or_path))\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized model identifier in Salesforce/codet5p-220m-bimodal. Should contains one of 'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', 'xlm', 'roberta', 'ctrl'"
     ]
    }
   ],
   "source": [
    "print(\"\\nCreating retrieval dataset\")\n",
    "#change language and path to dataset here\n",
    "_, _, test_dataset, code_dataset = create_dataset('dataset/CSN', \"ruby\")\n",
    "\n",
    "test_loader, code_loader = create_loader([test_dataset, code_dataset], [None, None],\n",
    "                                             batch_size=[256, 256],\n",
    "                                             num_workers=[4, 4], is_trains=[False, False], collate_fns=[None, None])\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5p-220m-bimodal\", trust_remote_code=True)\n",
    "tokenizer.enc_token_id = tokenizer.convert_tokens_to_ids('[ENC]')\n",
    "model = AutoModel.from_pretrained(\"Salesforce/codet5p-220m-bimodal\", trust_remote_code=True)\n",
    "print(f'Loaded Salesforce/codet5p-220m-bimodal model (#para={model.num_parameters()})')\n",
    "\n",
    "print('\\nStart zero-shot evaluation...')\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "text_feats = get_feats(model, tokenizer, test_loader, 64, device, modality='text',\n",
    "                           desc='Get text feats')\n",
    "code_feats = get_feats(model, tokenizer, code_loader, 360, device, modality='code',\n",
    "                           desc='Get code feats')\n",
    "\n",
    "test_result = match_evaluation(model, text_feats, code_feats, tokenizer, device, 32,\n",
    "                                   test_loader.dataset.text2code)\n",
    "print(f'\\n====> zero-shot test result: ', test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
