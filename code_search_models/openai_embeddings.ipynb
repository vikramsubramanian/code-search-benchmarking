{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai[embeddings]==0.27.7\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from data_utils import create_dataset, create_loader\n",
    "\n",
    "import openai\n",
    "#enter openai api key\n",
    "openai.api_key = (\"\")\n",
    "\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feats(data_loader, desc='Get feats'):\n",
    "    embeds = []\n",
    "    max_token_length = 29120\n",
    "\n",
    "    for text in tqdm(data_loader, total=len(data_loader), desc=desc):\n",
    "\n",
    "        for txt in text:\n",
    "            txt = txt[0:max_token_length]\n",
    "            embed = get_embedding(txt, engine='text-embedding-ada-002')\n",
    "            embeds.append(embed)\n",
    "\n",
    "    return embeds\n",
    "\n",
    "\n",
    "def contrast_evaluation(text_embeds, code_embeds, img2txt):\n",
    "    text_embeds = np.array(text_embeds)\n",
    "    code_embeds = np.array(code_embeds)\n",
    "    \n",
    "    # Initialize the score matrix\n",
    "    score_matrix_i2t = np.zeros((text_embeds.shape[0], code_embeds.shape[0]))\n",
    "\n",
    "    # Compute cosine similarity for each pair of embeddings\n",
    "    for i, text_embed in enumerate(text_embeds):\n",
    "        for j, code_embed in enumerate(code_embeds):\n",
    "            score_matrix_i2t[i, j] = cosine_similarity(text_embed, code_embed)\n",
    "\n",
    "    ranks = np.ones(score_matrix_i2t.shape[0]) * -1\n",
    "\n",
    "    for index, score in enumerate(score_matrix_i2t):\n",
    "        inds = np.argsort(score)[::-1]\n",
    "        ranks[index] = np.where(inds == img2txt[index])[0][0]\n",
    "\n",
    "\n",
    "    # Compute metrics\n",
    "    tr1 = 100.0 * len(np.where(ranks < 1)[0]) / len(ranks)\n",
    "    tr5 = 100.0 * len(np.where(ranks < 5)[0]) / len(ranks)\n",
    "    tr10 = 100.0 * len(np.where(ranks < 10)[0]) / len(ranks)\n",
    "    mrr = 100.0 * np.mean(1 / (ranks + 1))\n",
    "\n",
    "\n",
    "    eval_result = {'r1': tr1,\n",
    "                   'r5': tr5,\n",
    "                   'r10': tr10,\n",
    "                   'mrr': mrr}\n",
    "    return eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCreating retrieval dataset\")\n",
    "#change language and path to dataset here\n",
    "_, _, test_dataset, code_dataset = create_dataset('dataset', 'ruby')\n",
    "\n",
    "test_loader, code_loader = create_loader([test_dataset, code_dataset], [None, None],\n",
    "                                         batch_size=[128, 128],\n",
    "                                         num_workers=[4, 4], is_trains=[False, False], collate_fns=[None, None])\n",
    "\n",
    "\n",
    "print('\\nStart zero-shot evaluation...')\n",
    "\n",
    "text_embeds = get_feats(test_loader, desc='Get text feats')\n",
    "code_embeds = get_feats(code_loader, desc='Get code feats')\n",
    "test_result = contrast_evaluation(text_embeds, code_embeds, test_loader.dataset.text2code)\n",
    "\n",
    "print(f'\\n====> zero-shot test result: ', test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
